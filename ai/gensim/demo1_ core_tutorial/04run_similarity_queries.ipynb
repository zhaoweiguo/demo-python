{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Similarity Queries\n",
        "==================\n",
        "\n",
        "Demonstrates querying a corpus for similar documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the Corpus\n",
        "-------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-08 14:16:26,428 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2024-01-08 14:16:26,429 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
            "2024-01-08 14:16:26,429 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2024-01-08T14:16:26.429829', 'gensim': '4.3.2', 'python': '3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:07:22) [Clang 14.0.6 ]', 'platform': 'macOS-14.1.2-x86_64-i386-64bit', 'event': 'created'}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from gensim import corpora\n",
        "\n",
        "documents = [\n",
        "    \"Human machine interface for lab abc computer applications\",\n",
        "    \"A survey of user opinion of computer system response time\",\n",
        "    \"The EPS user interface management system\",\n",
        "    \"System and human system engineering testing of EPS\",\n",
        "    \"Relation of user perceived response time to error measurement\",\n",
        "    \"The generation of random binary unordered trees\",\n",
        "    \"The intersection graph of paths in trees\",\n",
        "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "    \"Graph minors A survey\",\n",
        "]\n",
        "\n",
        "# remove common words and tokenize\n",
        "stoplist = set('for a of the and to in'.split())\n",
        "texts = [\n",
        "    [word for word in document.lower().split() if word not in stoplist]\n",
        "    for document in documents\n",
        "]\n",
        "\n",
        "# remove words that appear only once\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "texts = [\n",
        "    [token for token in text if frequency[token] > 1]\n",
        "    for text in texts\n",
        "]\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarity interface\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-08 14:16:59,416 : INFO : using serial LSI version on this node\n",
            "2024-01-08 14:16:59,417 : INFO : updating model with new documents\n",
            "2024-01-08 14:16:59,418 : INFO : preparing a new chunk of documents\n",
            "2024-01-08 14:16:59,419 : INFO : using 100 extra samples and 2 power iterations\n",
            "2024-01-08 14:16:59,419 : INFO : 1st phase: constructing (12, 102) action matrix\n",
            "2024-01-08 14:16:59,421 : INFO : orthonormalizing (12, 102) action matrix\n",
            "2024-01-08 14:16:59,424 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
            "2024-01-08 14:16:59,425 : INFO : computing the final decomposition\n",
            "2024-01-08 14:16:59,426 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
            "2024-01-08 14:16:59,427 : INFO : processed documents up to #9\n",
            "2024-01-08 14:16:59,428 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
            "2024-01-08 14:16:59,428 : INFO : topic #1(2.542): 0.623*\"graph\" + 0.490*\"trees\" + 0.451*\"minors\" + 0.274*\"survey\" + -0.167*\"system\" + -0.141*\"eps\" + -0.113*\"human\" + 0.107*\"response\" + 0.107*\"time\" + -0.072*\"interface\"\n",
            "2024-01-08 14:16:59,429 : INFO : LsiModel lifecycle event {'msg': 'trained LsiModel<num_terms=12, num_topics=2, decay=1.0, chunksize=20000> in 0.01s', 'datetime': '2024-01-08T14:16:59.429184', 'gensim': '4.3.2', 'python': '3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:07:22) [Clang 14.0.6 ]', 'platform': 'macOS-14.1.2-x86_64-i386-64bit', 'event': 'created'}\n"
          ]
        }
      ],
      "source": [
        "from gensim import models\n",
        "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 本教程的目的只需了解有关 LSI 的两件事\n",
        "- 首先，这只是另一种变换：它将向量从一个空间变换到另一个空间。\n",
        "- 其次，LSI 的好处是能够识别术语（在我们的例子中是文档中的单词）和主题之间的模式和关系\n",
        "- 我们的 LSI 空间是二维的（num_topics = 2），因此有两个主题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0.4618210045327148), (1, -0.07002766527899958)]\n"
          ]
        }
      ],
      "source": [
        "doc = \"Human computer interaction\"\n",
        "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
        "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
        "print(vec_lsi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing query structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-08 14:31:12,926 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
            "2024-01-08 14:31:12,928 : INFO : creating matrix with 9 documents and 2 features\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<gensim.similarities.docsim.MatrixSimilarity at 0x1b62bf3d0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim import similarities\n",
        "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it\n",
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>\n",
        "仅当整个向量集适合内存时，类 similarities.MatrixSimilarity 才适用。例如，当与此类一起使用时，包含 100 万个文档的语料库将需要 256 维 LSI 空间中的 2GB RAM。\n",
        "</p>\n",
        "<p>\n",
        "如果没有 2GB 的可用 RAM，您将需要使用 similarities.Similarity 类。此类在固定内存中运行，通过将索引拆分到磁盘上的多个文件（称为分片）中。它在内部使用 similarities.MatrixSimilarity 和 similarities.SparseMatrixSimilarity ，因此它仍然很快，尽管稍微复杂一些。\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# 索引持久性是通过标准 save() 和 load() 函数处理的\n",
        "# 对于所有相似性索引类（ similarities.Similarity 、 similarities.MatrixSimilarity 和 similarities.SparseMatrixSimilarity ）都是如此\n",
        "index.save('/tmp/deerwester.index')\n",
        "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performing queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.998093  ,  0.93748635,  0.9984453 ,  0.9865886 ,  0.90755945,\n",
              "       -0.12416792, -0.10639259, -0.09879464,  0.05004176], dtype=float32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index[vec_lsi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
          ]
        }
      ],
      "source": [
        "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
        "print(list(enumerate(sims)))  # print(document_number, document_similarity)  2-tuples\n",
        "\n",
        "# 余弦测量返回 <-1, 1> 范围内的相似度（越大，越相似），因此第一个文档的得分为 0.998093"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9984453 The EPS user interface management system\n",
            "0.998093 Human machine interface for lab abc computer applications\n",
            "0.9865886 System and human system engineering testing of EPS\n",
            "0.93748635 A survey of user opinion of computer system response time\n",
            "0.90755945 Relation of user perceived response time to error measurement\n",
            "0.050041765 Graph minors A survey\n",
            "-0.09879464 Graph minors IV Widths of trees and well quasi ordering\n",
            "-0.10639259 The intersection graph of paths in trees\n",
            "-0.12416792 The generation of random binary unordered trees\n"
          ]
        }
      ],
      "source": [
        "# 将这些相似性按降序排列，并获得查询 “人机交互” 的最终答案\n",
        "sorted_sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "for doc_position, doc_score in sorted_sims:\n",
        "    print(doc_score, documents[doc_position])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如果使用 a standard boolean fulltext search 方法，那么 ``The EPS user interface management system`` 和 ``Relation of user perceived response time to error measurement`` 将不可能得分这么高，因为它俩与原文本 ``\"Human computer interaction\"`` 不共享任何常见单词。然而，在应用 LSI 后，我们可以观察到它们都获得了相当高的相似度分数。事实上，这种语义概括是我们首先应用转换和进行主题建模的原因。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
