{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "text_corpus = [\n",
        "    \"Human machine interface for lab abc computer applications\",\n",
        "    \"A survey of user opinion of computer system response time\",\n",
        "    \"The EPS user interface management system\",\n",
        "    \"System and human system engineering testing of EPS\",\n",
        "    \"Relation of user perceived response time to error measurement\",\n",
        "    \"The generation of random binary unordered trees\",\n",
        "    \"The intersection graph of paths in trees\",\n",
        "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "    \"Graph minors A survey\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
              " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'management', 'system'],\n",
              " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
              " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
              " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
              " ['intersection', 'graph', 'paths', 'trees'],\n",
              " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a set of frequent words\n",
        "stoplist = set('for a of the and to in'.split(' '))\n",
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text_corpus]\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['human', 'interface', 'computer'],\n",
            " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
            " ['eps', 'user', 'interface', 'system'],\n",
            " ['system', 'human', 'system', 'eps'],\n",
            " ['user', 'response', 'time'],\n",
            " ['trees'],\n",
            " ['graph', 'trees'],\n",
            " ['graph', 'minors', 'trees'],\n",
            " ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
        "pprint.pprint(processed_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'human': 2,\n",
              " 'interface': 2,\n",
              " 'computer': 2,\n",
              " 'survey': 2,\n",
              " 'user': 3,\n",
              " 'system': 4,\n",
              " 'response': 2,\n",
              " 'time': 2,\n",
              " 'eps': 2,\n",
              " 'trees': 3,\n",
              " 'graph': 3,\n",
              " 'minors': 2}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{k:v for k, v in frequency.items() if v>1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...>\n"
          ]
        }
      ],
      "source": [
        "# Before proceeding, we want to associate each word in the corpus with a unique integer ID. \n",
        "# This dictionary defines the vocabulary of all words that our processing knows about.\n",
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(processed_corpus)\n",
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'computer': 0,\n",
            " 'eps': 8,\n",
            " 'graph': 10,\n",
            " 'human': 1,\n",
            " 'interface': 2,\n",
            " 'minors': 11,\n",
            " 'response': 3,\n",
            " 'survey': 4,\n",
            " 'system': 5,\n",
            " 'time': 6,\n",
            " 'trees': 9,\n",
            " 'user': 7}\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(dictionary.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 2, 2: 2, 0: 2, 4: 2, 7: 3, 5: 3, 3: 2, 6: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary.dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('computer', 0),\n",
            " ('human', 1),\n",
            " ('interface', 2),\n",
            " ('response', 3),\n",
            " ('survey', 4),\n",
            " ('system', 5),\n",
            " ('time', 6),\n",
            " ('user', 7),\n",
            " ('eps', 8),\n",
            " ('trees', 9),\n",
            " ('graph', 10),\n",
            " ('minors', 11)]\n"
          ]
        }
      ],
      "source": [
        "sorted_words = sorted(dictionary.token2id.items(), key=lambda x: x[1])\n",
        "pprint.pprint(sorted_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1)]\n"
          ]
        }
      ],
      "source": [
        "# 使用 doc2bow 方法为文档创建词袋表示，该方法返回单词计数的稀疏表示\n",
        "# 未出现在矢量化中的单词将隐式表示为零(这儿就是 interaction 不在dictionary，所以隐式为0；又因为稀疏所以直接不显示)\n",
        "new_doc = \"Human computer interaction\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1)],\n",
            " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
            " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
            " [(1, 1), (5, 2), (8, 1)],\n",
            " [(3, 1), (6, 1), (7, 1)],\n",
            " [(9, 1)],\n",
            " [(9, 1), (10, 1)],\n",
            " [(9, 1), (10, 1), (11, 1)],\n",
            " [(4, 1), (10, 1), (11, 1)]]\n"
          ]
        }
      ],
      "source": [
        "# 将整个原始语料库转换为向量列表\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
        "pprint.pprint(bow_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(5, 0.5898341626740045), (11, 0.8075244024440723)]\n"
          ]
        }
      ],
      "source": [
        "# 使用模型 tf-idf\n",
        "# tf-idf 模型将向量从词袋表示转换为向量空间，其中频率计数根据语料库中每个单词的相对稀有度进行加权。\n",
        "from gensim import models\n",
        "\n",
        "# train the model\n",
        "# 对于 TfIdf，“训练” 只需浏览一次提供的语料库并计算其所有特征的文档频率\n",
        "# 训练其他模型，例如潜在语义分析或潜在狄利克雷分配，涉及更多，因此需要更多时间\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "\n",
        "# transform the \"system minors\" string\n",
        "words = \"system minors\".lower().split()\n",
        "print(tfidf[dictionary.doc2bow(words)])\n",
        "\n",
        "# 说明\n",
        "# ID corresponding to “system” has been weighted lower than the ID corresponding to “minors”\n",
        "# Because:\n",
        "#   (“system” occurred 4 times in the original corpus)\n",
        "#   (“minors” only occurred twice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.similarities.docsim.SparseMatrixSimilarity at 0x11cc419f0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 可以通过 TfIdf 转换整个语料库并对其进行索引，为相似性查询做准备\n",
        "from gensim import similarities\n",
        "\n",
        "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0.0), (1, 0.32448703), (2, 0.41707572), (3, 0.7184812), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "# 查询 query_document 与语料库中每个文档的相似度\n",
        "query_document = 'system engineering'.split()\n",
        "query_bow = dictionary.doc2bow(query_document)  # query_bow = [(5, 1)]  # 说明: system出现一次, engineering没有\n",
        "sims = index[tfidf[query_bow]]\n",
        "print(list(enumerate(sims)))    # 可以知道 'system engineering' 与如下语料库中的第4句最相似\n",
        "\n",
        "# 语料库内容\n",
        "# text_corpus = [\n",
        "#     \"Human machine interface for lab abc computer applications\",\n",
        "#     \"A survey of user opinion of computer system response time\",\n",
        "#     \"The EPS user interface management system\",\n",
        "#     \"System and human system engineering testing of EPS\",\n",
        "#     \"Relation of user perceived response time to error measurement\",\n",
        "#     \"The generation of random binary unordered trees\",\n",
        "#     \"The intersection graph of paths in trees\",\n",
        "#     \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "#     \"Graph minors A survey\",\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 0.7184812\n",
            "2 0.41707572\n",
            "1 0.32448703\n",
            "0 0.0\n",
            "4 0.0\n",
            "5 0.0\n",
            "6 0.0\n",
            "7 0.0\n",
            "8 0.0\n"
          ]
        }
      ],
      "source": [
        "# 通过排序使其更具可读性\n",
        "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
        "    print(document_number, score)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
