{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# From Strings to Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"Human machine interface for lab abc computer applications\",\n",
        "    \"A survey of user opinion of computer system response time\",\n",
        "    \"The EPS user interface management system\",\n",
        "    \"System and human system engineering testing of EPS\",\n",
        "    \"Relation of user perceived response time to error measurement\",\n",
        "    \"The generation of random binary unordered trees\",\n",
        "    \"The intersection graph of paths in trees\",\n",
        "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "    \"Graph minors A survey\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['human', 'interface', 'computer'],\n",
            " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
            " ['eps', 'user', 'interface', 'system'],\n",
            " ['system', 'human', 'system', 'eps'],\n",
            " ['user', 'response', 'time'],\n",
            " ['trees'],\n",
            " ['graph', 'trees'],\n",
            " ['graph', 'minors', 'trees'],\n",
            " ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint  # pretty-printer\n",
        "from collections import defaultdict\n",
        "\n",
        "# remove common words and tokenize\n",
        "stoplist = set('for a of the and to in'.split())\n",
        "texts = [\n",
        "    [word for word in document.lower().split() if word not in stoplist]\n",
        "    for document in documents\n",
        "]\n",
        "\n",
        "# remove words that appear only once\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "texts = [\n",
        "    [token for token in text if frequency[token] > 1]\n",
        "    for text in texts\n",
        "]\n",
        "\n",
        "pprint(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 17:37:06,691 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2023-12-29 17:37:06,692 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
            "2023-12-29 17:37:06,692 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-12-29T17:37:06.692632', 'gensim': '4.3.2', 'python': '3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:07:22) [Clang 14.0.6 ]', 'platform': 'macOS-14.1.2-x86_64-i386-64bit', 'event': 'created'}\n",
            "2023-12-29 17:37:06,693 : INFO : Dictionary lifecycle event {'fname_or_handle': '/tmp/deerwester.dict', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-12-29T17:37:06.693409', 'gensim': '4.3.2', 'python': '3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:07:22) [Clang 14.0.6 ]', 'platform': 'macOS-14.1.2-x86_64-i386-64bit', 'event': 'saving'}\n",
            "2023-12-29 17:37:06,696 : INFO : saved /tmp/deerwester.dict\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...>\n"
          ]
        }
      ],
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "dictionary.save('/tmp/deerwester.dict')  # store the dictionary, for future reference\n",
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
          ]
        }
      ],
      "source": [
        "print(dictionary.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1)]\n"
          ]
        }
      ],
      "source": [
        "new_doc = \"Human computer interaction\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 17:41:10,650 : INFO : storing corpus in Matrix Market format to /tmp/deerwester.mm\n",
            "2023-12-29 17:41:10,651 : INFO : saving sparse matrix to /tmp/deerwester.mm\n",
            "2023-12-29 17:41:10,652 : INFO : PROGRESS: saving document #0\n",
            "2023-12-29 17:41:10,653 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
            "2023-12-29 17:41:10,654 : INFO : saving MmCorpus index to /tmp/deerwester.mm.index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
          ]
        }
      ],
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)  # store to disk, for later use\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus Streaming – One Document at a Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from smart_open import open  # for transparently opening remote files\n",
        "\n",
        "\n",
        "class MyCorpus:\n",
        "    def __iter__(self):\n",
        "        for line in open('https://radimrehurek.com/mycorpus.txt'):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield dictionary.doc2bow(line.lower().split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This flexibility allows you to create your own corpus classes that stream the documents directly from disk, network, database, dataframes... \n",
        "# The models in Gensim are implemented such that they don't require all vectors to reside in RAM at once.\n",
        "# You can even create the documents on the fly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.MyCorpus object at 0x1a3a01300>\n"
          ]
        }
      ],
      "source": [
        "corpus_memory_friendly = MyCorpus()  # doesn't load the corpus into memory!\n",
        "print(corpus_memory_friendly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1)]\n",
            "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
            "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
            "[(1, 1), (5, 2), (8, 1)]\n",
            "[(3, 1), (6, 1), (7, 1)]\n",
            "[(9, 1)]\n",
            "[(9, 1), (10, 1)]\n",
            "[(9, 1), (10, 1), (11, 1)]\n",
            "[(4, 1), (10, 1), (11, 1)]\n"
          ]
        }
      ],
      "source": [
        "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
        "    print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 17:50:02,665 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2023-12-29 17:50:02,666 : INFO : built Dictionary<42 unique tokens: ['abc', 'applications', 'computer', 'for', 'human']...> from 9 documents (total 69 corpus positions)\n",
            "2023-12-29 17:50:02,666 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<42 unique tokens: ['abc', 'applications', 'computer', 'for', 'human']...> from 9 documents (total 69 corpus positions)\", 'datetime': '2023-12-29T17:50:02.666799', 'gensim': '4.3.2', 'python': '3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:07:22) [Clang 14.0.6 ]', 'platform': 'macOS-14.1.2-x86_64-i386-64bit', 'event': 'created'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...>\n"
          ]
        }
      ],
      "source": [
        "# collect statistics about all tokens\n",
        "dictionary = corpora.Dictionary(line.lower().split() for line in open('https://radimrehurek.com/mycorpus.txt'))\n",
        "# remove stop words and words that appear only once\n",
        "stop_ids = [\n",
        "    dictionary.token2id[stopword]\n",
        "    for stopword in stoplist\n",
        "    if stopword in dictionary.token2id\n",
        "]\n",
        "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]\n",
        "dictionary.filter_tokens(stop_ids + once_ids)  # remove stop words and words that appear only once\n",
        "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'computer': 0,\n",
              " 'human': 1,\n",
              " 'interface': 2,\n",
              " 'response': 3,\n",
              " 'survey': 4,\n",
              " 'system': 5,\n",
              " 'time': 6,\n",
              " 'user': 7,\n",
              " 'eps': 8,\n",
              " 'trees': 9,\n",
              " 'graph': 10,\n",
              " 'minors': 11}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary.token2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 2, 2: 2, 0: 2, 4: 2, 7: 3, 5: 3, 3: 2, 6: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary.dfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Corpus Formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 18:02:29,056 : INFO : storing corpus in Matrix Market format to /tmp/corpus.mm\n",
            "2023-12-29 18:02:29,058 : INFO : saving sparse matrix to /tmp/corpus.mm\n",
            "2023-12-29 18:02:29,058 : INFO : PROGRESS: saving document #0\n",
            "2023-12-29 18:02:29,059 : INFO : saved 2x2 matrix, density=25.000% (1/4)\n",
            "2023-12-29 18:02:29,060 : INFO : saving MmCorpus index to /tmp/corpus.mm.index\n"
          ]
        }
      ],
      "source": [
        "corpus = [[(1, 0.5)], []]  # make one document empty, for the heck of it\n",
        "\n",
        "corpora.MmCorpus.serialize('/tmp/corpus.mm', corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 18:08:17,785 : INFO : converting corpus to SVMlight format: /tmp/corpus.svmlight\n",
            "2023-12-29 18:08:17,787 : INFO : saving SvmLightCorpus index to /tmp/corpus.svmlight.index\n",
            "2023-12-29 18:08:17,788 : INFO : no word id mapping provided; initializing from corpus\n",
            "2023-12-29 18:08:17,790 : INFO : storing corpus in Blei's LDA-C format into /tmp/corpus.lda-c\n",
            "2023-12-29 18:08:17,792 : INFO : saving vocabulary of 2 words to /tmp/corpus.lda-c.vocab\n",
            "2023-12-29 18:08:17,793 : INFO : saving BleiCorpus index to /tmp/corpus.lda-c.index\n",
            "2023-12-29 18:08:17,794 : INFO : no word id mapping provided; initializing from corpus\n",
            "2023-12-29 18:08:17,795 : INFO : storing corpus in List-Of-Words format into /tmp/corpus.low\n",
            "2023-12-29 18:08:17,796 : WARNING : List-of-words format can only save vectors with integer elements; 1 float entries were truncated to integer value\n",
            "2023-12-29 18:08:17,797 : INFO : saving LowCorpus index to /tmp/corpus.low.index\n"
          ]
        }
      ],
      "source": [
        "# 其他格式包括 Joachim 的 SVMlight 格式、Blei 的 LDA-C 格式和 GibbsLDA++ 格式\n",
        "corpora.SvmLightCorpus.serialize('/tmp/corpus.svmlight', corpus)\n",
        "corpora.BleiCorpus.serialize('/tmp/corpus.lda-c', corpus)\n",
        "corpora.LowCorpus.serialize('/tmp/corpus.low', corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-29 18:08:14,580 : INFO : loaded corpus index from /tmp/corpus.mm.index\n",
            "2023-12-29 18:08:14,581 : INFO : initializing cython corpus reader from /tmp/corpus.mm\n",
            "2023-12-29 18:08:14,583 : INFO : accepted corpus with 2 documents, 2 features, 1 non-zero entries\n"
          ]
        }
      ],
      "source": [
        "corpus = corpora.MmCorpus('/tmp/corpus.mm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MmCorpus(2 documents, 2 features, 1 non-zero entries)\n"
          ]
        }
      ],
      "source": [
        "# Corpus objects are streams, so typically you won’t be able to print them directly\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(1, 0.5)], []]\n"
          ]
        }
      ],
      "source": [
        "# one way of printing a corpus: load it entirely into memory\n",
        "print(list(corpus))  # calling list() will convert any sequence to a plain Python list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 0.5)]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# another way of doing it: print one document at a time, making use of the streaming interface\n",
        "for doc in corpus:\n",
        "    print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpora.BleiCorpus.serialize('/tmp/corpus.lda-c', corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compatibility with NumPy and SciPy\n",
        "#### NumPy示例\n",
        "- Gensim also contains [efficient utility functions](https://radimrehurek.com/gensim/matutils.html) to help converting from/to numpy matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "numpy_matrix = np.random.randint(10, size=[5, 2])  # random matrix as an example(创建一个矩阵)\n",
        "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
        "# numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=number_of_corpus_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [8 3]\n",
            " [9 9]\n",
            " [0 2]\n",
            " [1 9]]\n",
            "[[(0, 1.0), (1, 8.0), (2, 9.0), (4, 1.0)], [(0, 2.0), (1, 3.0), (2, 9.0), (3, 2.0), (4, 9.0)]]\n"
          ]
        }
      ],
      "source": [
        "print(numpy_matrix)\n",
        "print(list(corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SciPy示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import scipy.sparse\n",
        "scipy_sparse_matrix = scipy.sparse.random(5, 2)  # random sparse matrix as example(创建一个稀疏矩阵)\n",
        "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
        "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[[], []]\n"
          ]
        }
      ],
      "source": [
        "print(scipy_sparse_matrix)\n",
        "print(list(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (1, 0)\t0.05808361216819946\n",
            "  (3, 1)\t0.15599452033620265\n",
            "密集矩阵的内容：\n",
            "[[0.         0.        ]\n",
            " [0.05808361 0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.15599452]\n",
            " [0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import scipy.sparse\n",
        "# density：指定非零元素的密度\n",
        "# format：指定返回的矩阵的格式，这里选择压缩稀疏行（CSR）格式\n",
        "# random_state：为了可重复性，可以设置随机数生成器的种子\n",
        "sparse_matrix=scipy.sparse.random(5, 2, density=0.25, format='csr', random_state=42)\n",
        "print(\"稀疏矩阵的内容：\")\n",
        "print(sparse_matrix)\n",
        "dense_matrix = sparse_matrix.toarray()\n",
        "print(\"密集矩阵的内容：\")\n",
        "print(dense_matrix)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
